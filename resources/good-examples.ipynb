{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good examples and tips in Edward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code that works and is useful, that I didn't want to throw away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi: [0.24454049 0.46987182 0.13792581 0.14766188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [100%] ██████████████████████████████ Elapsed: 6s | Loss: 43.773\n",
      "Inferred pi: [0.29658943 0.33174667 0.22883385 0.14283012]\n"
     ]
    }
   ],
   "source": [
    "# code from edward/examples/dirichlet_categorical.py:\n",
    "# Inferring a categorical distribution with KLqp\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "K = 4\n",
    "N = 30\n",
    "# DATA\n",
    "pi_true = np.random.dirichlet(np.array([20.0, 30.0, 10.0, 10.0]))\n",
    "z_data = np.array([np.random.choice(K, 1, p=pi_true)[0]\n",
    "                   for n in range(N)])\n",
    "print(\"pi: {}\".format(pi_true))\n",
    "\n",
    "# MODEL\n",
    "pi = ed.models.Dirichlet(tf.ones(4))\n",
    "z = ed.models.Categorical(probs=pi, sample_shape=N)\n",
    "\n",
    "# INFERENCE\n",
    "qpi = ed.models.Dirichlet(tf.nn.softplus(\n",
    "    tf.get_variable(\"qpi/concentration\", [K])))\n",
    "\n",
    "inference = ed.KLqp({pi: qpi}, data={z: z_data})\n",
    "inference.run(n_iter=1500, n_samples=30)\n",
    "\n",
    "# sess = ed.get_session()\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \"\"\"\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 8s | Acceptance Rate: 1.000\n"
     ]
    }
   ],
   "source": [
    "# example from examples/bayesian_linear_regression_sghmc.py\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "def build_toy_dataset(N, noise_std=0.5):\n",
    "    X = np.concatenate([np.linspace(0, 2, num=N / 2),\n",
    "                        np.linspace(6, 8, num=N / 2)])\n",
    "    y = 2.0 * X + 10 * np.random.normal(0, noise_std, size=N)\n",
    "    X = X.astype(np.float32).reshape((N, 1))\n",
    "    y = y.astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 1  # number of features\n",
    "# DATA\n",
    "X_train, y_train = build_toy_dataset(N)\n",
    "X_test, y_test = build_toy_dataset(N)\n",
    "\n",
    "# MODEL\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = ed.models.Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "b = ed.models.Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "y = ed.models.Normal(loc=ed.dot(X, w) + b, scale=tf.ones(N))\n",
    "\n",
    "# INFERENCE\n",
    "T = 5000                        # Number of samples.\n",
    "nburn = 100                     # Number of burn-in samples.\n",
    "stride = 10                     # Frequency with which to plot samples.\n",
    "qw = ed.models.Empirical(params=tf.Variable(tf.random_normal([T, D])))\n",
    "qb = ed.models.Empirical(params=tf.Variable(tf.random_normal([T, 1])))\n",
    "\n",
    "inference = ed.SGHMC({w: qw, b: qb}, data={X: X_train, y: y_train})\n",
    "inference.run(step_size=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Markov Chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from issue https://github.com/blei-lab/edward/issues/450\n",
    "from edward.models import Categorical, Dirichlet, Uniform, Mixture\n",
    "\n",
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_hidden], 1.0 / n_hidden))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_hidden, n_hidden])), dim=0)\n",
    "\n",
    "# emission matrix\n",
    "E = tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs, n_hidden])), dim=0)\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "y = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[:, x_tm1])\n",
    "    y_t = Categorical(probs=E[:, x_t])\n",
    "    x.append(x_t)\n",
    "    y.append(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42720532 0.37529522 0.29069752]\n",
      " [0.20214134 0.34706113 0.3367309 ]\n",
      " [0.3706533  0.27764365 0.3725716 ]]\n",
      "20000/20000 [100%] ██████████████████████████████ Elapsed: 107s | Loss: 10.563\n",
      "[[0.8985785  0.03703917 0.03406724]\n",
      " [0.00348154 0.9607762  0.09740151]\n",
      " [0.09793993 0.00218464 0.8685312 ]]\n",
      "[[9.9671930e-01 1.9515709e-03 2.1848876e-03]\n",
      " [1.7951096e-03 1.2189067e-03 9.9692792e-01]\n",
      " [1.4855342e-03 9.9682957e-01 8.8716898e-04]]\n",
      "[array([0.9960776 , 0.0024412 , 0.00148117], dtype=float32), array([9.9728549e-01, 1.8385181e-03, 8.7593711e-04], dtype=float32), array([9.9807847e-01, 1.0312266e-03, 8.9030614e-04], dtype=float32), array([0.9966865 , 0.0017852 , 0.00152831], dtype=float32), array([0.9966016 , 0.0014918 , 0.00190652], dtype=float32), array([9.9790359e-01, 9.5059699e-04, 1.1458463e-03], dtype=float32), array([0.9974504 , 0.00139323, 0.0011563 ], dtype=float32), array([0.9974974 , 0.00111923, 0.00138342], dtype=float32), array([9.9841952e-01, 8.1004773e-04, 7.7040045e-04], dtype=float32), array([0.99220324, 0.00111062, 0.00668607], dtype=float32), array([0.00482394, 0.00125331, 0.99392277], dtype=float32), array([1.0225778e-03, 9.2023355e-04, 9.9805719e-01], dtype=float32), array([0.00117362, 0.00113399, 0.99769247], dtype=float32), array([7.7024673e-04, 1.9842167e-04, 9.9903131e-01], dtype=float32), array([0.0013318 , 0.00104346, 0.9976247 ], dtype=float32), array([6.5106561e-04, 4.1685646e-04, 9.9893206e-01], dtype=float32), array([1.0831788e-03, 3.4776086e-04, 9.9856901e-01], dtype=float32), array([2.273914e-03, 6.358411e-04, 9.970902e-01], dtype=float32), array([9.0079213e-04, 6.2336837e-04, 9.9847585e-01], dtype=float32), array([0.00168717, 0.0027686 , 0.99554425], dtype=float32), array([9.1571111e-04, 9.9745685e-01, 1.6274209e-03], dtype=float32), array([5.247183e-04, 9.986305e-01, 8.447890e-04], dtype=float32), array([5.9271744e-04, 9.9852008e-01, 8.8727201e-04], dtype=float32), array([7.0620701e-04, 9.9896073e-01, 3.3305865e-04], dtype=float32), array([5.9400854e-04, 9.9880111e-01, 6.0480332e-04], dtype=float32), array([8.306088e-04, 9.986512e-01, 5.181944e-04], dtype=float32), array([7.5984187e-04, 9.9876910e-01, 4.7102777e-04], dtype=float32), array([1.0499307e-03, 9.9861681e-01, 3.3322000e-04], dtype=float32), array([9.1070356e-04, 9.9853826e-01, 5.5101799e-04], dtype=float32), array([1.3592112e-03, 9.9826944e-01, 3.7133825e-04], dtype=float32)]\n",
      "[array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([0.9967193 , 0.00179511, 0.00148553], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32), array([2.1848876e-03, 9.9692792e-01, 8.8716898e-04], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_hidden))))\n",
    "      for _ in range(chain_len)]\n",
    "\n",
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "y_data = map(np.array, y_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(T))\n",
    "\n",
    "    inference = ed.KLqp(dict(zip(x, qx)), dict(zip(y, y_data)))\n",
    "    inference.run(n_iter=20000)\n",
    "\n",
    "    print(sess.run(T))\n",
    "    print(sess.run(E))\n",
    "    print(sess.run([foo.probs for foo in qx]))\n",
    "    print(sess.run([foo.probs for foo in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this example seems to converge to something better that whay the guy said in the github example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Given my 3 hidden states, 3 observation types, and long changes of identical observations, I expect transition matrix to be close to diagonal and the emission matrix to look like a permutation matrix. I see non-converging loss info:*\n",
    "\n",
    "Iteration     1 [  0%]: Loss = 35.123\n",
    "Iteration  2000 [ 10%]: Loss = 46.565\n",
    "Iteration  4000 [ 20%]: Loss = 47.923\n",
    "Iteration  6000 [ 30%]: Loss = 56.581\n",
    "Iteration  8000 [ 40%]: Loss = 53.431\n",
    "Iteration 10000 [ 50%]: Loss = 49.397\n",
    "Iteration 12000 [ 60%]: Loss = 55.551\n",
    "Iteration 14000 [ 70%]: Loss = 47.537\n",
    "Iteration 16000 [ 80%]: Loss = 47.690\n",
    "Iteration 18000 [ 90%]: Loss = 47.107\n",
    "Iteration 20000 [100%]: Loss = 38.514\n",
    "\n",
    "*, non-uniform state probability distributions, and very uniform observation probabilities. Any idea what's going wrong in my setup or the solving of the problem?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What data did we pass in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "# for each categorical var y, he associated this matrix:\n",
    "np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
