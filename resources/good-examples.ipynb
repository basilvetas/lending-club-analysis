{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good examples and tips in Edward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code that works and is useful, that I didn't want to throw away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi: [0.24454049 0.46987182 0.13792581 0.14766188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [100%] ██████████████████████████████ Elapsed: 6s | Loss: 43.773\n",
      "Inferred pi: [0.29658943 0.33174667 0.22883385 0.14283012]\n"
     ]
    }
   ],
   "source": [
    "# code from edward/examples/dirichlet_categorical.py:\n",
    "# Inferring a categorical distribution with KLqp\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "K = 4\n",
    "N = 30\n",
    "# DATA\n",
    "pi_true = np.random.dirichlet(np.array([20.0, 30.0, 10.0, 10.0]))\n",
    "z_data = np.array([np.random.choice(K, 1, p=pi_true)[0]\n",
    "                   for n in range(N)])\n",
    "print(\"pi: {}\".format(pi_true))\n",
    "\n",
    "# MODEL\n",
    "pi = ed.models.Dirichlet(tf.ones(4))\n",
    "z = ed.models.Categorical(probs=pi, sample_shape=N)\n",
    "\n",
    "# INFERENCE\n",
    "qpi = ed.models.Dirichlet(tf.nn.softplus(\n",
    "    tf.get_variable(\"qpi/concentration\", [K])))\n",
    "\n",
    "inference = ed.KLqp({pi: qpi}, data={z: z_data})\n",
    "inference.run(n_iter=1500, n_samples=30)\n",
    "\n",
    "# sess = ed.get_session()\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \"\"\"\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 8s | Acceptance Rate: 1.000\n"
     ]
    }
   ],
   "source": [
    "# example from examples/bayesian_linear_regression_sghmc.py\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "def build_toy_dataset(N, noise_std=0.5):\n",
    "    X = np.concatenate([np.linspace(0, 2, num=N / 2),\n",
    "                        np.linspace(6, 8, num=N / 2)])\n",
    "    y = 2.0 * X + 10 * np.random.normal(0, noise_std, size=N)\n",
    "    X = X.astype(np.float32).reshape((N, 1))\n",
    "    y = y.astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 1  # number of features\n",
    "# DATA\n",
    "X_train, y_train = build_toy_dataset(N)\n",
    "X_test, y_test = build_toy_dataset(N)\n",
    "\n",
    "# MODEL\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = ed.models.Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "b = ed.models.Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "y = ed.models.Normal(loc=ed.dot(X, w) + b, scale=tf.ones(N))\n",
    "\n",
    "# INFERENCE\n",
    "T = 5000                        # Number of samples.\n",
    "nburn = 100                     # Number of burn-in samples.\n",
    "stride = 10                     # Frequency with which to plot samples.\n",
    "qw = ed.models.Empirical(params=tf.Variable(tf.random_normal([T, D])))\n",
    "qb = ed.models.Empirical(params=tf.Variable(tf.random_normal([T, 1])))\n",
    "\n",
    "inference = ed.SGHMC({w: qw, b: qb}, data={X: X_train, y: y_train})\n",
    "inference.run(step_size=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Markov Chain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HMM, code from github issue, working:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from issue https://github.com/blei-lab/edward/issues/450\n",
    "from edward.models import Categorical, Dirichlet, Uniform, Mixture\n",
    "\n",
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_hidden], 1.0 / n_hidden))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_hidden, n_hidden])), dim=0)\n",
    "\n",
    "# emission matrix\n",
    "E = tf.nn.softmax(tf.Variable(tf.random_uniform([n_hidden, n_obs])), dim=0)\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "y = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[x_tm1, :])\n",
    "    y_t = Categorical(probs=E[x_t, :])\n",
    "    x.append(x_t)\n",
    "    y.append(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3364298  0.33027482 0.32518175]\n",
      " [0.31573606 0.33219975 0.2646786 ]\n",
      " [0.34783414 0.33752543 0.41013962]]\n",
      "20000/20000 [100%] ██████████████████████████████ Elapsed: 110s | Loss: 10.638\n",
      "[[0.88519555 0.10100932 0.04295716]\n",
      " [0.00688317 0.8933158  0.03535395]\n",
      " [0.10792119 0.00567483 0.9216889 ]]\n",
      "[[0.00692124 0.9866714  0.00451739]\n",
      " [0.00276657 0.00459809 0.993371  ]\n",
      " [0.9903122  0.00873054 0.00211151]]\n",
      "[array([0.00655151, 0.00263566, 0.99081284], dtype=float32), array([0.00522245, 0.00172166, 0.9930559 ], dtype=float32), array([0.00439227, 0.00145458, 0.9941532 ], dtype=float32), array([0.00415663, 0.00165063, 0.9941928 ], dtype=float32), array([0.00509683, 0.00291023, 0.99199295], dtype=float32), array([0.00467363, 0.00116577, 0.9941606 ], dtype=float32), array([0.00453563, 0.00167482, 0.9937895 ], dtype=float32), array([0.00417722, 0.0023592 , 0.99346364], dtype=float32), array([0.00486003, 0.00171187, 0.99342805], dtype=float32), array([0.01455432, 0.00245372, 0.982992  ], dtype=float32), array([0.98116827, 0.00220935, 0.01662241], dtype=float32), array([0.99130744, 0.00206588, 0.00662671], dtype=float32), array([0.9920482 , 0.00181543, 0.0061363 ], dtype=float32), array([0.99209577, 0.00160734, 0.00629691], dtype=float32), array([0.9913994 , 0.00204769, 0.006553  ], dtype=float32), array([0.99219114, 0.00246523, 0.00534355], dtype=float32), array([0.99226236, 0.00223478, 0.00550277], dtype=float32), array([0.9921028 , 0.00181732, 0.0060799 ], dtype=float32), array([0.9896006 , 0.0033153 , 0.00708403], dtype=float32), array([0.977662  , 0.01643801, 0.00589988], dtype=float32), array([0.01036164, 0.98574907, 0.00388933], dtype=float32), array([2.3630259e-03, 9.9707186e-01, 5.6511827e-04], dtype=float32), array([0.00290681, 0.995739  , 0.0013543 ], dtype=float32), array([0.00286255, 0.99602   , 0.00111745], dtype=float32), array([0.00243626, 0.9960865 , 0.00147733], dtype=float32), array([0.00304489, 0.99506605, 0.001889  ], dtype=float32), array([0.00199197, 0.9965785 , 0.00142953], dtype=float32), array([0.00192264, 0.99681985, 0.00125744], dtype=float32), array([0.00222985, 0.99674964, 0.00102052], dtype=float32), array([0.002854  , 0.99515486, 0.00199111], dtype=float32)]\n",
      "[array([0.00692124, 0.9866714 , 0.00451739], dtype=float32), array([0.00692124, 0.9866714 , 0.00451739], dtype=float32), array([0.00692124, 0.9866714 , 0.00451739], dtype=float32), array([0.00692124, 0.9866714 , 0.00451739], dtype=float32), array([0.00692124, 0.9866714 , 0.00451739], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.9903122 , 0.00873054, 0.00211151], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32), array([0.00276657, 0.00459809, 0.993371  ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_hidden))))\n",
    "      for _ in range(chain_len)]\n",
    "\n",
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "y_data = map(np.array, y_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(T))\n",
    "\n",
    "    inference = ed.KLqp(dict(zip(x, qx)), dict(zip(y, y_data)))\n",
    "    inference.run(n_iter=20000)\n",
    "\n",
    "    print(sess.run(T))\n",
    "    print(sess.run(E))\n",
    "    print(sess.run([foo.probs for foo in qx]))\n",
    "    print(sess.run([foo.probs for foo in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this example seems to converge to something better that whay the guy said in the github example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Given my 3 hidden states, 3 observation types, and long changes of identical observations, I expect transition matrix to be close to diagonal and the emission matrix to look like a permutation matrix. I see non-converging loss info:*\n",
    "\n",
    "Iteration     1 [  0%]: Loss = 35.123\n",
    "Iteration  2000 [ 10%]: Loss = 46.565\n",
    "Iteration  4000 [ 20%]: Loss = 47.923\n",
    "Iteration  6000 [ 30%]: Loss = 56.581\n",
    "Iteration  8000 [ 40%]: Loss = 53.431\n",
    "Iteration 10000 [ 50%]: Loss = 49.397\n",
    "Iteration 12000 [ 60%]: Loss = 55.551\n",
    "Iteration 14000 [ 70%]: Loss = 47.537\n",
    "Iteration 16000 [ 80%]: Loss = 47.690\n",
    "Iteration 18000 [ 90%]: Loss = 47.107\n",
    "Iteration 20000 [100%]: Loss = 38.514\n",
    "\n",
    "*, non-uniform state probability distributions, and very uniform observation probabilities. Any idea what's going wrong in my setup or the solving of the problem?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What data did we pass in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "# for each categorical var y, he associated this matrix:\n",
    "np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transitions: you almost always stay in the same state. Emission: you almost always go to the same state, but it doesn't have to be the same number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the external loop like this seems to work, fixing the length of the chains is not a big problem (anyway at some point LC stops the loan anyway so they cannot run indefinitely), we could do that while thinking of how to make it more efficient inside TF.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HMM, initial code from github issue, not working:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "x_0 = Categorical(probs=tf.fill([n_hidden], 1.0 / n_hidden))\n",
    "\n",
    "# transition matrix\n",
    "T = Uniform(tf.zeros([n_hidden, n_hidden]), tf.ones([n_hidden, n_hidden]))\n",
    "T /= tf.reduce_sum(T, axis=0, keep_dims=True)\n",
    "\n",
    "# emission matrix\n",
    "E = Uniform(tf.zeros([n_obs, n_hidden]), tf.ones([n_obs, n_hidden]))\n",
    "E /= tf.reduce_sum(E, axis=0, keep_dims=True)\n",
    "\n",
    "# model\n",
    "y_val = tf.placeholder(tf.int32, [chain_len])\n",
    "x = tf.scan(lambda x_tm1, _: Categorical(probs=T[:, x_tm1]),\n",
    "            y_val, initializer=x_0)\n",
    "y = tf.map_fn(lambda x_t: Categorical(probs=E[:, x_t]), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tensor' object has no attribute 'reparameterization_type'\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "qT = tf.Variable(Uniform(tf.zeros([n_hidden, n_hidden]), tf.ones([n_hidden, n_hidden])))\n",
    "qT /= tf.reduce_sum(qT, axis=0, keep_dims=True)\n",
    "qE = tf.Variable(Uniform(tf.zeros([n_obs, n_hidden]), tf.ones([n_obs, n_hidden])))\n",
    "qE /= tf.reduce_sum(qE, axis=0, keep_dims=True)\n",
    "px_init = tf.Variable(tf.random_uniform([chain_len, n_hidden]))\n",
    "px_init /= tf.reduce_sum(px_init, axis=0, keep_dims=True)\n",
    "qx = Categorical(probs=px_init)\n",
    "\n",
    "y_data = np.array(([0] * 10) + ([1] * 10) + ([2] * 10), dtype=np.int32)\n",
    "\n",
    "inference = ed.KLqp({T: qT, E: qE, x: qx}, {y_val: y_data})\n",
    "try:\n",
    "    inference.run()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems similar to the github issue (**but not exactly the same error as back then)**. It's because many of these objects are not instances of RandomVariable... If we dig in more into how Edward works we might understand why exactly and if there is anyway to avoid this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular Markov Model, based on the code above (without the hidden states):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from issue https://github.com/blei-lab/edward/issues/450\n",
    "chain_len = 30\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_obs], 1.0 / n_obs))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs, n_obs])), dim=0)\n",
    "\n",
    "# no more emissions, we observe directly the hidden states x\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[:, x_tm1])\n",
    "    x.append(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33800068 0.49874976 0.4133891 ]\n",
      " [0.34657052 0.261219   0.3996655 ]\n",
      " [0.31542882 0.24003124 0.1869454 ]]\n",
      "20000/20000 [100%] ██████████████████████████████ Elapsed: 87s | Loss: 0.073\n",
      "[[0.22719203 0.22574067 0.22214726]\n",
      " [0.25503868 0.25731292 0.26435006]\n",
      " [0.51776934 0.51694643 0.51350266]]\n",
      "qx:\n",
      "[array([0.21782018, 0.25254372, 0.52963614], dtype=float32),\n",
      " array([0.23656154, 0.24698423, 0.5164543 ], dtype=float32),\n",
      " array([0.23196688, 0.26875463, 0.49927852], dtype=float32),\n",
      " array([0.22545192, 0.268244  , 0.5063041 ], dtype=float32),\n",
      " array([0.2388351 , 0.2530424 , 0.50812244], dtype=float32),\n",
      " array([0.22195865, 0.27552202, 0.50251937], dtype=float32),\n",
      " array([0.22381088, 0.25734565, 0.5188435 ], dtype=float32),\n",
      " array([0.23569892, 0.25882402, 0.5054771 ], dtype=float32),\n",
      " array([0.2143386 , 0.24603303, 0.5396283 ], dtype=float32),\n",
      " array([0.23597272, 0.23802604, 0.5260012 ], dtype=float32),\n",
      " array([0.23711358, 0.24408403, 0.51880246], dtype=float32),\n",
      " array([0.22456102, 0.25244418, 0.5229948 ], dtype=float32),\n",
      " array([0.22219501, 0.27283803, 0.504967  ], dtype=float32),\n",
      " array([0.21317768, 0.26393768, 0.52288467], dtype=float32),\n",
      " array([0.23586342, 0.24596529, 0.51817137], dtype=float32),\n",
      " array([0.23754594, 0.28015307, 0.48230106], dtype=float32),\n",
      " array([0.22599714, 0.23019312, 0.5438097 ], dtype=float32),\n",
      " array([0.2079136 , 0.26926577, 0.5228206 ], dtype=float32),\n",
      " array([0.191129 , 0.2768843, 0.5319867], dtype=float32),\n",
      " array([0.22160101, 0.2463809 , 0.53201807], dtype=float32),\n",
      " array([0.22140564, 0.2508832 , 0.5277112 ], dtype=float32),\n",
      " array([0.19529234, 0.27549586, 0.52921176], dtype=float32),\n",
      " array([0.22837095, 0.26879394, 0.50283515], dtype=float32),\n",
      " array([0.2331646 , 0.23427501, 0.53256035], dtype=float32),\n",
      " array([0.2346712 , 0.24712767, 0.5182011 ], dtype=float32),\n",
      " array([0.22669545, 0.28312603, 0.49017856], dtype=float32),\n",
      " array([0.24002951, 0.2561316 , 0.50383896], dtype=float32),\n",
      " array([0.23115796, 0.26583213, 0.50301   ], dtype=float32),\n",
      " array([0.23268786, 0.27170447, 0.4956076 ], dtype=float32),\n",
      " array([0.2159013 , 0.2701204 , 0.51397824], dtype=float32)]\n",
      "x:\n",
      "[array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22719203, 0.25503868, 0.51776934], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22214726, 0.26435006, 0.51350266], dtype=float32),\n",
      " array([0.22574067, 0.25731292, 0.51694643], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_obs))))\n",
    "      for _ in range(chain_len)]\n",
    "\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(T))\n",
    "\n",
    "    inference = ed.KLqp(dict(zip(x, qx)), dict(zip(x, x_data)))\n",
    "    inference.run(n_iter=20000)\n",
    "\n",
    "    print(sess.run(T))\n",
    "    print('qx:')\n",
    "    pprint(sess.run([foo.probs for foo in qx]))\n",
    "    print('x:')\n",
    "    pprint(sess.run([foo.probs for foo in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
