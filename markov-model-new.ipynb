{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogenous (stationary) Markov Chain Implementation in Edward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Imports and Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from edward.models import Bernoulli, Categorical, Normal, Empirical, Multinomial\n",
    "\n",
    "from utils.utils import load_dataframe, load_data_dic, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby(['term', 'age_of_loan', 'loan_status']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently active loans\n",
    "df_active = df.loc[df.age_of_loan < df.term.astype(int)].reset_index(drop=True)\n",
    "df_inactive = df.loc[~(df.age_of_loan < df.term.astype(int))].reset_index(drop=True)\n",
    "df_active.shape[0] + df_inactive.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inactive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_active.age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_inactive.age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split active loans by 36 and 60 month terms\n",
    "df_active_36 = df_active.loc[df_active.term.astype(int) == 36]\n",
    "df_active_60 = df_active.loc[df_active.term.astype(int) == 60]\n",
    "df_active_36.shape[0] + df_active_60.shape[0] == df_active.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active_36.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active_60.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_active_36.age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_active_60.age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"loan_status\", data=df_active_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"loan_status\", data=df_active_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_active_36.loc[df_active_36.loan_status == 'Current'].age_of_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late = (df_active_36.loan_status == 'Late (16-30 days)') | (df_active_36.loan_status == 'Late (31-120 days)')\n",
    "sns.distplot(df_active_36.loc[late].age_of_loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_status.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** it might be good to use panda's Categorical type instead of sklearn's label encoder so we have the mapping between indew and category directly from the dataframe (or modify the preprocess function to return the label encoder objects too, but then it means we also need to cache them which is not super clean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = df.loan_status.unique()\n",
    "n_statuses = len(statuses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generating the transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't take too long (took me a while to figure out a clean way to do it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['previous_month'] = df.age_of_loan - 1\n",
    "transitions =  pd.merge(df, df, left_on=['id', 'age_of_loan'], right_on=['id', 'previous_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Solving with MLE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLE solution to a markov chain is simply the empirical counts, so easy to implement. This can give us a good baseline to check our bayesian results later:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: count the transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts = pd.crosstab(transitions['loan_status_x'],\n",
    "                                transitions['loan_status_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: transform the count dataframe to a count matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that row 0 is missing, we add it by hand and set it to 0. Same with column 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_statuses):\n",
    "    if i not in transition_counts.index:\n",
    "        # if no row, create it and set to 0:\n",
    "        print('Filling in row %s ...' % (i,))\n",
    "        transition_counts.loc[i] = 0\n",
    "    if i not in transition_counts.columns:\n",
    "        # if no column, create it and set to 0:\n",
    "        print('Filling in column %s ...' % (i,))\n",
    "        transition_counts[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-sort the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts.sort_index(axis=0, inplace=True)\n",
    "transition_counts.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note with crosstab we could have gotten the frequencies directly, but having this raw count table might be useful for the Bayesian case.\n",
    "\n",
    "We can also get the margins directly (sum by row), but then sort_index fails..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_mle = transition_counts.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(transitions_mle.shape[0]):\n",
    "    n_i_all = sum(transitions_mle[i,:]) # count how many i => j for this i and any j\n",
    "    if n_i_all != 0:\n",
    "        transitions_mle[i,:] *= (1/n_i_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(transitions_mle, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bayesian Estimation, Multinomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the paper \"Markov Chain Models for Delinquency: Transition Matrix Estimation and Forecasting\", Scott D. Grimshaw, William P. Alexander, Section 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model the counts of the transitions with a multinomial. More specifically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call $f(j)$ the row vector of monthly movements: $f(j,k)$ is the number of accounts that start the month in state $j$ and move to state $k$. We model this vector's distribution as a multinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial follows probabilities, denoted as $p(j,k)$ in the paper, that are the probability of each individual transition j => k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the prior is the Dirichlet distribution with parameters $\\alpha(j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts.iloc[1,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition counts, per month:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts_per_month = transitions.groupby(['previous_month_x', 'loan_status_x', 'loan_status_y']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list()\n",
    "for month in transition_counts_per_month.index.levels[0]:\n",
    "    temp.append(transition_counts_per_month[month].unstack().fillna(0))\n",
    "transition_counts_per_month = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts_per_month[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counts in transition_counts_per_month:\n",
    "    for i in range(n_statuses):\n",
    "        if i not in counts.index:\n",
    "            # if no row, create it and set to 0:\n",
    "            # print('Filling in row %s ...' % (i,))\n",
    "            counts.loc[i] = 0\n",
    "        if i not in counts.columns:\n",
    "            # if no column, create it and set to 0:\n",
    "            # print('Filling in column %s ...' % (i,))\n",
    "            counts[i] = 0\n",
    "    counts.sort_index(axis=0, inplace=True)\n",
    "    counts.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts_per_month[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_accounts = df.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "data = np.array([month_counts.iloc[2,:].values for month_counts in transition_counts_per_month])\n",
    "\n",
    "# MODEL\n",
    "# trying to build a model just for the first row:\n",
    "pi = ed.models.Dirichlet(tf.ones(n_statuses))\n",
    "\n",
    "# TODO define counts for each row\n",
    "# (since there aren't too many rows we can just do a loop instead of using a matrix)\n",
    "# total_count is the number of individual draws for each sample of the multinomial\n",
    "counts = ed.models.Multinomial(total_count=data.sum(axis=1).astype(np.float32), probs=pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In all the edward example they tend to create the variables with tf.get_variable rather than tf.Variable. This will create a new var if no var with the same name already exist, and otherwise re-use the older one. I don't like this that much when experimenting, because it can become a mess, you have to call reset_default_graph often... At least for the Inference part, I created the variables with tf.Var() instead, because we need to overwrite qpi (for example) multiple times:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Variational Inference (KLqp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example I found used tf.nn.softplus, not sure why exactly, need to check..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference.run() method for KLqp takes as input n_samples = Number of samples from variational model for calculating stochastic gradients. I left it to 1 for now (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qpi = ed.models.Dirichlet(tf.nn.softplus(tf.get_variable(\"qpi/concentration\", [n_statuses])), name=\"qpi\")\n",
    "qpi = ed.models.Dirichlet(\n",
    "    tf.nn.softplus(tf.Variable(name=\"qpi/concentration\",\n",
    "                               expected_shape=[n_statuses],\n",
    "                               initial_value=tf.constant(1.0/n_statuses, shape=[n_statuses]))), name=\"qpi\")\n",
    "\n",
    "inference = ed.KLqp({pi: qpi}, data={counts: data})\n",
    "inference.run(n_iter=500)\n",
    "\n",
    "# CRITICISM\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, I got it to randomly converge to this: [0.66669214 0.02093365 0.10725855 0.01944017 0.06792089 0.04235639 0.04178157 0.03361673]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without tf.nn.softplus, same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qpi = ed.models.Dirichlet(tf.get_variable(\"qpi/concentration\", [n_statuses]), name=\"qpi\")\n",
    "qpi = ed.models.Dirichlet(tf.Variable(name=\"qpi/concentration\",\n",
    "                               expected_shape=[n_statuses],\n",
    "                               initial_value=tf.constant(1.0/n_statuses, shape=[n_statuses])), name=\"qpi\")\n",
    "\n",
    "inference = ed.KLqp({pi: qpi}, data={counts: data})\n",
    "inference.run(n_iter=500)\n",
    "\n",
    "# CRITICISM\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it converges to nan loss and nan qpi, sometimes it converges to bad results... need to figure this out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 MCMC: HMC (\"black box\" Monte Carlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails, the error is related to https://github.com/blei-lab/edward/issues/785.\n",
    "I think the error is linked to the fact that dirichlet is actually defined in a k-1 dimensional space (because vectors need to sum up to 1).\n",
    "\n",
    "In Edward MCMC requires that latent vars have \"unconstrained support\" (see edward/inferences/hmc.py). They say that setting auto_transform=True should make the vars unconstrained and fix the problem...\n",
    "\n",
    "About auto_transform: *Automated transformations provide convenient handling of constrained continuous variables during inference by transforming them to an unconstrained space. Automated transformations are crucial for expanding the scope of algorithm classes such as gradient-based Monte Carlo and variational inference with reparameterization gradients.*\n",
    "\n",
    "But it doesn't seem to work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 5000 # number of posterior samples => the \"M\" in our lecture on MCMC (length of MC used for inference)\n",
    "\n",
    "# the approximating family has to be an empirical distribution in MCMC:\n",
    "# qpi = ed.models.Empirical(params=tf.get_variable(\"qpi/params\", [T, n_statuses],\n",
    "#       initializer=tf.constant_initializer(1.0 / n_statuses))) # initialize as uniform probs\n",
    "qpi = ed.models.Empirical(tf.Variable(name=\"qpi/params\", expected_shape=[T, n_statuses],\n",
    "                                      initial_value=tf.constant(1.0/n_statuses, shape=[T, n_statuses])))\n",
    "\n",
    "inference = ed.inferences.HMC(latent_vars={pi: qpi}, data={counts: data}) # passing auto_transform fails\n",
    "inference.run(step_size=1e-3)\n",
    "\n",
    "# CRITICISM\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MCMC: Gibbs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define qpi similarly as for HMC (Empirical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 5000 # number of posterior samples => the \"M\" in our lecture on MCMC (length of MC used for inference)\n",
    "\n",
    "# the approximating family has to be an empirical distribution in MCMC:\n",
    "# qpi = ed.models.Empirical(params=tf.get_variable(\"qpi/params\", [T, n_statuses],\n",
    "#       initializer=tf.constant_initializer(1.0 / n_statuses))) # initialize as uniform probs\n",
    "qpi = ed.models.Empirical(tf.Variable(name=\"qpi/params\", expected_shape=[T, n_statuses],\n",
    "                                      initial_value=tf.constant(1.0/n_statuses, shape=[T, n_statuses])))\n",
    "\n",
    "# self.qu = ed.models.Empirical(params=tf.Variable(tf.zeros([n_iter, self.N, self.K]), name=\"qu\"))\n",
    "inference = ed.inferences.Gibbs(latent_vars={pi: qpi}, data={counts: data})\n",
    "inference.run()\n",
    "\n",
    "# CRITICISM\n",
    "print(\"Inferred pi: {}\".format(sess.run(qpi.mean()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem pretty good so that's promising!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Figure out with HMC fails\n",
    "- Figure out why KLqp fails (but maybe we can leave that for later)\n",
    "- Run Gibbs but for the full model i.e. one multinomial per row, with a list of variables\n",
    "- Run Gibbs for the full model but with a matrix\n",
    "\n",
    "- Develop our model more\n",
    "- Stop using the multinomial model and formalize directly as a Markov Model, as in https://github.com/blei-lab/edward/issues/450.\n",
    "- Think about criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian Estimation, Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
