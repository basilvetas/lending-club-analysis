{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Model in Edward - mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since good-examples was becoming messy I'm putting here different approaches to make inference work on a small Markov Model example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO check out tips here: https://discourse.edwardlib.org/t/variational-em-for-independent-factor-analysis/61/2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Always use tf.nn.softmax or softplus when initializing the parameters of a Dirichlet to make sure that during the inference the params stay >0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from pprint import pprint\n",
    "\n",
    "from edward.models import Categorical, Dirichlet, Uniform, Mixture\n",
    "from edward.models import Bernoulli, Normal\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mock data used:** One trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "# for each categorical var y, he associated this matrix:\n",
    "np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Without Dirichlet Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if it works, not ideal because we do want to have priors..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: [doesn't work] HMM, with Transition matrix + TF loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= initial code form Github issue: https://github.com/blei-lab/edward/issues/450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run it we get a similar error as the github issue (**but not exactly the same error as back then)**. It's because many of these objects are not instances of RandomVariable... If we dig in more into how Edward works we might understand why exactly and if there is anyway to avoid this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: [works and converges] HMM, with Transition matrix + Python loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-36a708141b0f>:9: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "# from issue \n",
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_hidden], 1.0 / n_hidden))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_hidden, n_hidden])), dim=0)\n",
    "\n",
    "# emission matrix\n",
    "E = tf.nn.softmax(tf.Variable(tf.random_uniform([n_hidden, n_obs])), dim=0)\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "y = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[x_tm1, :])\n",
    "    y_t = Categorical(probs=E[x_t, :])\n",
    "    x.append(x_t)\n",
    "    y.append(y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4184508  0.34765527 0.342746  ]\n",
      " [0.34079152 0.23904131 0.27410343]\n",
      " [0.2407577  0.41330343 0.3831506 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 33s | Loss: 20.932\n",
      "[[0.7177787  0.11977834 0.71373457]\n",
      " [0.02416126 0.83216935 0.02445475]\n",
      " [0.2580601  0.04805234 0.26181066]]\n",
      "[[0.00221619 0.00382671 0.4800893 ]\n",
      " [0.9941004  0.9893936  0.0040356 ]\n",
      " [0.0036834  0.00677973 0.5158751 ]]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_hidden))))\n",
    "      for _ in range(chain_len)]\n",
    "\n",
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "y_data = map(np.array, y_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(T))\n",
    "\n",
    "    inference = ed.KLqp(dict(zip(x, qx)), dict(zip(y, y_data)))\n",
    "    inference.run(n_iter=5000)\n",
    "\n",
    "    inferred_T, inferred_E = sess.run([T, E])\n",
    "    inferred_qx = sess.run([foo.probs for foo in qx])\n",
    "    inferred_y_probs = sess.run([foo.probs for foo in y])\n",
    "    print(inferred_T)\n",
    "    print(inferred_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this example seems to converge to something better that whay the guy said in the github example. Also I switched column indexing to rows. **Sometimes it doesn't seem to actually converge. When it converges, it reaches a loss between 7 and 10**. 5K iterations seems to be enough. Less seemed not to converge but not sure if by re-running it wouldn't do better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Given my 3 hidden states, 3 observation types, and long changes of identical observations, I expect transition matrix to be close to diagonal and the emission matrix to look like a permutation matrix. I see non-converging loss info. (the guy had a loss around 40, for 10K iterations)*, *non-uniform state probability distributions, and very uniform observation probabilities. Any idea what's going wrong in my setup or the solving of the problem?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transitions: you almost always stay in the same state. Emission: you almost always go to the same state, but it doesn't have to be the same number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the external loop like this seems to work, fixing the length of the chains is not a big problem (anyway at some point LC stops the loan anyway so they cannot run indefinitely), we could do that while thinking of how to make it more efficient inside TF.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3: [works but bad results] Regular MM, with Transition matrix + Python loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= Version 2 but without hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-28d5871ab39c>:7: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "chain_len = 30\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_obs], 1.0 / n_obs))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs, n_obs])), dim=0)\n",
    "\n",
    "# no more emissions, we observe directly the hidden states x\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[:, x_tm1])\n",
    "    x.append(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/util/random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 29s | Loss: 0.327\n",
      "[[0.25940156 0.25781873 0.25737822]\n",
      " [0.39562166 0.3987041  0.40426505]\n",
      " [0.34497678 0.34347713 0.33835673]]\n",
      "[array([0.28284925, 0.37504154, 0.34210923], dtype=float32), array([0.24529925, 0.397335  , 0.35736576], dtype=float32), array([0.25999007, 0.391565  , 0.34844494], dtype=float32), array([0.26203665, 0.39059556, 0.34736785], dtype=float32), array([0.26528502, 0.39197695, 0.34273797], dtype=float32), array([0.2525565, 0.3708744, 0.376569 ], dtype=float32), array([0.28238606, 0.3569442 , 0.3606698 ], dtype=float32), array([0.26020128, 0.4162674 , 0.32353133], dtype=float32), array([0.28147265, 0.37403712, 0.34449026], dtype=float32), array([0.24512741, 0.41684347, 0.33802906], dtype=float32), array([0.24144918, 0.39873162, 0.35981923], dtype=float32), array([0.23814194, 0.43193477, 0.32992324], dtype=float32), array([0.26426604, 0.38210905, 0.35362488], dtype=float32), array([0.24521352, 0.39080426, 0.36398217], dtype=float32), array([0.23679863, 0.43929908, 0.3239023 ], dtype=float32), array([0.29514426, 0.38579363, 0.3190621 ], dtype=float32), array([0.28542486, 0.420427  , 0.29414815], dtype=float32), array([0.27797395, 0.37310687, 0.3489192 ], dtype=float32), array([0.2366708 , 0.43922254, 0.32410657], dtype=float32), array([0.24614088, 0.43545914, 0.31840006], dtype=float32), array([0.27021864, 0.38420904, 0.3455724 ], dtype=float32), array([0.27293548, 0.3996818 , 0.32738274], dtype=float32), array([0.2811836 , 0.41112438, 0.30769205], dtype=float32), array([0.24900499, 0.3877661 , 0.36322892], dtype=float32), array([0.2546421 , 0.42422423, 0.32113364], dtype=float32), array([0.25436622, 0.41153574, 0.3340981 ], dtype=float32), array([0.2683131 , 0.40637207, 0.3253148 ], dtype=float32), array([0.25819016, 0.35855174, 0.38325804], dtype=float32), array([0.290235  , 0.37779972, 0.33196536], dtype=float32), array([0.2272284 , 0.42136553, 0.35140607], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_obs))))\n",
    "      for _ in range(chain_len)]\n",
    "\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    # print(sess.run(T))\n",
    "\n",
    "    inference = ed.KLqp(dict(zip(x, qx)), dict(zip(x, x_data)))\n",
    "    inference.run(n_iter=5000)\n",
    "\n",
    "    inferred_T = sess.run(T)\n",
    "    inferred_qx = sess.run([foo.probs for foo in qx])\n",
    "    print(inferred_T)\n",
    "    print(inferred_qx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3.2: [?] Regular MM, with Transition matrix + Python loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_len = 30\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(probs=tf.fill([n_obs], 1.0 / n_obs))\n",
    "\n",
    "# transition matrix\n",
    "T = tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs, n_obs]),\n",
    "                              trainable=False), dim=0)\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=T[:, x_tm1])\n",
    "    x.append(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_len = 30\n",
    "n_obs = 3\n",
    "\n",
    "x = [Categorical(probs=tf.fill([n_obs], 1.0 / n_obs)) for _ in range(chain_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 61s | Loss: -0.007\n",
      "[[0.26643828 0.34438336 0.22928569]\n",
      " [0.26327008 0.3921638  0.35276103]\n",
      " [0.4702917  0.26345286 0.41795328]]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "# qx = [Categorical(probs=tf.nn.softmax(tf.Variable(tf.ones(n_obs))))\n",
    "#       for _ in range(chain_len)]\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# MODEL\n",
    "qT = tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs, n_obs])), dim=0)\n",
    "qx = []\n",
    "qx_0 = Categorical(probs=tf.nn.softmax(tf.Variable(tf.random_uniform([n_obs]))))\n",
    "for _ in range(chain_len):\n",
    "    qx_tm1 = qx[-1] if qx else qx_0\n",
    "    qx_t = Categorical(probs=qT[:, qx_tm1])\n",
    "    qx.append(qx_t)\n",
    "\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # print(sess.run(T))\n",
    "    \n",
    "    latent_vars_map = dict(zip(x, qx))\n",
    "    # latent_vars_map.update({T: qT})\n",
    "    inference = ed.KLqp(latent_vars_map, data=dict(zip(x, x_data)))\n",
    "    inference.run(n_iter=5000, n_samples=10)\n",
    "\n",
    "    inferred_qT = sess.run(qT)\n",
    "    print(inferred_qT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With Dirichlet Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4: [works!] Regular MM + Python loop + Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(Dirichlet(tf.ones(n_hidden)))\n",
    "\n",
    "# transition matrix\n",
    "pi_T = [Dirichlet(tf.ones(n_hidden)) for i in range(n_hidden)]\n",
    "T = [Categorical(probs=pi) for pi in pi_T]\n",
    "\n",
    "# MODEL\n",
    "x = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = ed.models.Mixture(cat=Categorical(probs=tf.one_hot(x_tm1, n_hidden)), components=T)\n",
    "    x.append(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE (VI)**: WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [100%] ██████████████████████████████ Elapsed: 12s | Loss: 23.476\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "# qpi_T = [Dirichlet(tf.nn.softmax(tf.Variable(tf.ones(n_hidden)))) for i in range(n_hidden)]\n",
    "qpi_T = [Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_hidden)))) for i in range(n_hidden)]\n",
    "\n",
    "latent_vars_map = dict(zip(pi_T, qpi_T))\n",
    "\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    inference = ed.KLqp(latent_vars_map, dict(zip(x, x_data)))\n",
    "    inference.run(n_iter=500)\n",
    "    inferred_qpi_T = sess.run([qpi.mean() for qpi in qpi_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.6658835 , 0.14985795, 0.18425858], dtype=float32),\n",
       " array([0.14769787, 0.6268977 , 0.22540449], dtype=float32),\n",
       " array([0.19821896, 0.09202534, 0.7097557 ], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_qpi_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE (MCMC)**: DOESN'T WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "conjugate_log_prob not implemented for <class 'abc.Mixture'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/conjugacy/conjugacy.py\u001b[0m in \u001b[0;36mget_log_joint\u001b[0;34m(cond_set)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Use log prob tensor if already built in graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mconjugate_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3653\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3654\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3519\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3520\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3521\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'conjugate_log_joint/Mixture_17/_conjugate_log_prob:0' refers to a Tensor which does not exist. The operation, 'conjugate_log_joint/Mixture_17/_conjugate_log_prob', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b883c965b800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# inference = ed.inferences.MetropolisHastings(latent_vars_map, dict(zip(y, y_data)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGibbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vars_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minferred_qpi_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqpi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqpi_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/gibbs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_vars, proposal_vars, data)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproposal_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       proposal_vars = {z: complete_conditional(z)\n\u001b[0;32m---> 46\u001b[0;31m                        for z in six.iterkeys(latent_vars)}\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mcheck_latent_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/gibbs.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproposal_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       proposal_vars = {z: complete_conditional(z)\n\u001b[0;32m---> 46\u001b[0;31m                        for z in six.iterkeys(latent_vars)}\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mcheck_latent_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/conjugacy/conjugacy.py\u001b[0m in \u001b[0;36mcomplete_conditional\u001b[0;34m(rv, cond_set)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'complete_conditional_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# log_joint holds all the information we need to get a conditional.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mlog_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Pull out the nodes that are nonlinear functions of rv into s_stats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/conjugacy/conjugacy.py\u001b[0m in \u001b[0;36mget_log_joint\u001b[0;34m(cond_set)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conjugate_log_prob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m           raise NotImplementedError(\"conjugate_log_prob not implemented for\"\n\u001b[0;32m--> 190\u001b[0;31m                                     \" {}\".format(type(b)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mconjugate_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: conjugate_log_prob not implemented for <class 'abc.Mixture'>"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "T = 5000 # number of MCMC samples\n",
    "\n",
    "# Maybe this is not the right way to initialize:\n",
    "qpi_T = [ed.models.Empirical(\n",
    "    tf.Variable(expected_shape=[n_hidden],\n",
    "                initial_value=tf.constant(1.0/n_hidden, shape=[T, n_hidden]))) for i in range(n_hidden)]\n",
    "\n",
    "latent_vars_map = dict(zip(pi_T, qpi_T))\n",
    "\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # inference = ed.inferences.MetropolisHastings(latent_vars_map, dict(zip(y, y_data)))\n",
    "    inference = ed.inferences.Gibbs(latent_vars_map, data=dict(zip(x, x_data)))\n",
    "    inference.run()\n",
    "    inferred_qpi_T = sess.run([qpi.mean() for qpi in qpi_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.333344, 0.333344, 0.333344], dtype=float32),\n",
       " array([0.333344, 0.333344, 0.333344], dtype=float32),\n",
       " array([0.333344, 0.333344, 0.333344], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_qpi_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 5: [don't know if works] HMM, without Transition matrix + Dirichlet + Python loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Edward seems to be designed to know when to do EM when necessary, here we need to do EM because we don't observe the hidden state, we need to look more into that and see if it will figure it out or if we need to do it ourselves (instantiate two inference objects, and run alternatively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "chain_len = 30\n",
    "n_hidden = 3\n",
    "n_obs = 3\n",
    "\n",
    "x_0 = Categorical(Dirichlet(tf.ones(n_hidden)))\n",
    "\n",
    "# transition matrix\n",
    "pi_T = [Dirichlet(tf.ones(n_hidden)) for i in range(n_hidden)]\n",
    "T = [Categorical(probs=pi) for pi in pi_T]\n",
    "\n",
    "# emission matrix\n",
    "pi_E = [Dirichlet(tf.ones(n_obs)) for i in range(n_obs)]\n",
    "E = [Categorical(probs=pi) for pi in pi_E]\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = ed.models.Mixture(cat=Categorical(probs=tf.one_hot(x_tm1, n_hidden)), components=T)\n",
    "    y_t = ed.models.Mixture(cat=Categorical(probs=tf.one_hot(x_t, n_hidden)), components=E)\n",
    "    x.append(x_t)\n",
    "    y.append(y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE (VI) ON BOTH QPIT and QPIE** RESULTS NOT THAT GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 43s | Loss: 37.294\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qpi_T = [Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_hidden)))) for i in range(n_hidden)]\n",
    "qpi_E = [Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_obs)))) for i in range(n_hidden)]\n",
    "\n",
    "latent_vars_map = dict(zip(pi_T, qpi_T))\n",
    "latent_vars_map.update(dict(zip(pi_E, qpi_E)))\n",
    "\n",
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "y_data = map(np.array, y_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    inference = ed.KLqp(latent_vars_map, data=dict(zip(y, y_data)))\n",
    "    inference.run(n_iter=5000)\n",
    "    inferred_qpi_T = sess.run([qpi.mean() for qpi in qpi_T])\n",
    "    inferred_qpi_E = sess.run([qpi.mean() for qpi in qpi_E])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.5163122 , 0.19137841, 0.29230946], dtype=float32),\n",
       " array([0.4316325 , 0.20450503, 0.3638625 ], dtype=float32),\n",
       " array([0.2909255 , 0.18665254, 0.522422  ], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_qpi_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.35055286, 0.38690096, 0.26254615], dtype=float32),\n",
       " array([0.31107655, 0.37114182, 0.31778166], dtype=float32),\n",
       " array([0.45351365, 0.251756  , 0.29473028], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_qpi_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE (VI) ON ONLY QPIT:** RESULTS NOT THAT GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 43s | Loss: 44.499\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "qpi_T = [Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_hidden)))) for i in range(n_hidden)]\n",
    "# qpi_E = [Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_obs)))) for i in range(n_hidden)]\n",
    "\n",
    "latent_vars_map = dict(zip(pi_T, qpi_T))\n",
    "# latent_vars_map.update(dict(zip(pi_E, qpi_E)))\n",
    "\n",
    "y_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "y_data = map(np.array, y_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    inference = ed.KLqp(latent_vars_map, data=dict(zip(y, y_data)))\n",
    "    inference.run(n_iter=5000)\n",
    "    inferred_qpi_T = sess.run([qpi.mean() for qpi in qpi_T])\n",
    "    # inferred_qpi_E = sess.run([qpi.mean() for qpi in qpi_E])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.2658316 , 0.440889  , 0.29327947], dtype=float32),\n",
       " array([0.5744874 , 0.08134261, 0.34417003], dtype=float32),\n",
       " array([0.2542029 , 0.46512648, 0.2806706 ], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_qpi_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 6: [don't know if works] MM, Dirichlet generating the whole matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 3\n",
    "\n",
    "pi_0 = Dirichlet(tf.ones(n_states))\n",
    "x_0 = Categorical(pi_0)\n",
    "\n",
    "# transition matrix\n",
    "pi_T = Dirichlet(tf.ones([n_states, n_states]))\n",
    "\n",
    "x = []\n",
    "for _ in range(chain_len):\n",
    "    x_tm1 = x[-1] if x else x_0\n",
    "    x_t = Categorical(probs=tf.gather(pi_T, x_tm1))\n",
    "    x.append(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpi_0 = Dirichlet(tf.nn.softplus(tf.Variable(tf.ones(n_states))))\n",
    "qpi_T = Dirichlet(tf.nn.softplus(tf.Variable(tf.ones([n_states, n_states]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KLqp is going to copy each x, and see that they depend on the output of pi_T, and replace that output by the output of qpi_T. Problem: do the copied x still depend on each other? Not sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value data_387/Variable\n\t [[Node: data_387/Variable/read = Identity[T=DT_INT32, _class=[\"loc:@data_387/Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_387/Variable)]]\n\nCaused by op 'data_387/Variable/read', defined at:\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-35-49042b065138>\", line 5, in <module>\n    inference = ed.KLqp({pi_0: qpi_0, pi_T: qpi_T}, data=dict(zip(x, x_data)))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 84, in __init__\n    super(KLqp, self).__init__(latent_vars, data)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 27, in __init__\n    super(VariationalInference, self).__init__(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/inference.py\", line 93, in __init__\n    var = tf.Variable(ph, trainable=False, collections=[])\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 391, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3053, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value data_387/Variable\n\t [[Node: data_387/Variable/read = Identity[T=DT_INT32, _class=[\"loc:@data_387/Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_387/Variable)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value data_387/Variable\n\t [[Node: data_387/Variable/read = Identity[T=DT_INT32, _class=[\"loc:@data_387/Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_387/Variable)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-49042b065138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, variables, use_coordinator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0minfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/variational_inference.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value data_387/Variable\n\t [[Node: data_387/Variable/read = Identity[T=DT_INT32, _class=[\"loc:@data_387/Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_387/Variable)]]\n\nCaused by op 'data_387/Variable/read', defined at:\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-35-49042b065138>\", line 5, in <module>\n    inference = ed.KLqp({pi_0: qpi_0, pi_T: qpi_T}, data=dict(zip(x, x_data)))\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 84, in __init__\n    super(KLqp, self).__init__(latent_vars, data)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 27, in __init__\n    super(VariationalInference, self).__init__(*args, **kwargs)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/edward/inferences/inference.py\", line 93, in __init__\n    var = tf.Variable(ph, trainable=False, collections=[])\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 391, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3053, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/jeromekafrouni/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value data_387/Variable\n\t [[Node: data_387/Variable/read = Identity[T=DT_INT32, _class=[\"loc:@data_387/Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_387/Variable)]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "x_data = ([0] * 10) + ([1] * 10) + ([2] * 10)\n",
    "x_data = map(np.array, x_data)\n",
    "\n",
    "inference = ed.KLqp({pi_0: qpi_0, pi_T: qpi_T}, data=dict(zip(x, x_data)))\n",
    "\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    inference.run(n_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other tutorials/ideas we might consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementation of HMM but not suited for inference: https://gist.github.com/fredcallaway/c7252b6326dfb502e70cad4146731aef\n",
    "- Implementation of HMM by creating a custom RV class: might work but needs a lot of work, the code doesn't run as is: https://discourse.edwardlib.org/t/hmm-implementation-with-marginalized-latent-states/755\n",
    "- Using a list of categoricals and then using tf.gather to select from this list: Doesn't work, because tf.gather makes us loose the type so we no longer have Categorical variables => can't run inference (we can still sample though)\n",
    "- Using the OneHotCategorical RV instead of a Categorical RV and then taking tf.one_hot of it didn't seem to change much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom RV non hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a RV that takes as input a categorical RV which depends on a Dirichlet\n",
    "=> when doing KLqp, the alg will copy this RV and replace the dirichlet by the proposal dirichlet since it will be one of its ancestors. And then get the likelihood of the whole trajectory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distribution_HMM(Distribution):\n",
    "  def __init__(self, transmat, init_p, states, name='', *args, **kwargs):\n",
    "      self.transmat = transmat\n",
    "      self.init_p = init_p\n",
    "      self.states = states\n",
    "      parameters = locals()\n",
    "      parameters.pop(\"self\")\n",
    "\n",
    "      super(distribution_HMM, self).__init__(dtype=tf.float32,\n",
    "                                reparameterization_type=FULLY_REPARAMETERIZED,\n",
    "                                validate_args=False,\n",
    "                                allow_nan_stats=False,\n",
    "                                parameters=parameters,\n",
    "                                name=name, *args, **kwargs)\n",
    "\n",
    "  def normal_log_prob(self, X, mu, scale=1.):\n",
    "      return -.5 * tf.log(2. * np.pi) - tf.log(scale) - (1. / (2. * scale ** 2)) * (X - mu) ** 2\n",
    "\n",
    "  def _log_prob(self, value):\n",
    "      # first we need to compute the (len(obs), len(states)) matrix that holds the\n",
    "      # likelihood of each observation coming from each state\n",
    "      B_list = []\n",
    "      for j in range(0, self.transmat.shape[1]):\n",
    "          state_probs = self.normal_log_prob(mu=self.states[j], X=value)\n",
    "          B_list.append(state_probs)\n",
    "      B = tf.squeeze(tf.stack(B_list, axis=1))\n",
    "\n",
    "      alpha_0 = self.init_p + B[0]\n",
    "      logprob = tf.scan(\n",
    "          lambda alpha, b: tf.reduce_logsumexp(tf.transpose(alpha) + self.transmat, axis=0, keepdims=True) + b,\n",
    "          initializer=alpha_0,\n",
    "          elems=B[1:, :],\n",
    "          back_prop=True,\n",
    "          parallel_iterations=12,\n",
    "          infer_shape=False)\n",
    "      return tf.reduce_logsumexp(logprob[-1])\n",
    "\n",
    "  def _sample_n(self, n, seed=None):\n",
    "      raise NotImplementedError(\"_sample_n is not implemented\")\n",
    "\n",
    "class HMM(RandomVariable, distribution_HMM):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "      RandomVariable.__init__(self, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distribution_MM(Distribution):\n",
    "    def __init__(self, transmat, init_p, states, name='', *args, **kwargs):\n",
    "        self.transmat = transmat\n",
    "        self.init_p = init_p\n",
    "        self.states = states\n",
    "        parameters = locals()\n",
    "        parameters.pop(\"self\")\n",
    "\n",
    "        super(distribution_HMM, self).__init__(dtype=tf.float32,\n",
    "                                reparameterization_type=FULLY_REPARAMETERIZED,\n",
    "                                validate_args=False,\n",
    "                                allow_nan_stats=False,\n",
    "                                parameters=parameters,\n",
    "                                name=name, *args, **kwargs)\n",
    "\n",
    "    # def normal_log_prob(self, X, mu, scale=1.):\n",
    "    #   return -.5 * tf.log(2. * np.pi) - tf.log(scale) - (1. / (2. * scale ** 2)) * (X - mu) ** 2\n",
    "\n",
    "    def _log_prob(self, value):\n",
    "      # first we need to compute the (len(obs), len(states)) matrix that holds the\n",
    "      # likelihood of each observation coming from each state\n",
    "      B_list = []\n",
    "      for j in range(0, self.transmat.shape[1]):\n",
    "          state_probs = self.normal_log_prob(mu=self.states[j], X=value)\n",
    "          B_list.append(state_probs)\n",
    "      B = tf.squeeze(tf.stack(B_list, axis=1))\n",
    "\n",
    "      alpha_0 = self.init_p + B[0]\n",
    "      logprob = tf.scan(\n",
    "          lambda alpha, b: tf.reduce_logsumexp(tf.transpose(alpha) + self.transmat, axis=0, keepdims=True) + b,\n",
    "          initializer=alpha_0,\n",
    "          elems=B[1:, :],\n",
    "          back_prop=True,\n",
    "          parallel_iterations=12,\n",
    "          infer_shape=False)\n",
    "      return tf.reduce_logsumexp(logprob[-1])\n",
    "\n",
    "  def _sample_n(self, n, seed=None):\n",
    "      raise NotImplementedError(\"_sample_n is not implemented\")\n",
    "\n",
    "class HMM(RandomVariable, distribution_HMM):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "      RandomVariable.__init__(self, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.scan(\n",
    "    fn,\n",
    "    elems,\n",
    "    initializer=None,\n",
    "    parallel_iterations=10,\n",
    "    back_prop=True,\n",
    "    swap_memory=False,\n",
    "    infer_shape=True,\n",
    "    reverse=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.constant([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_function(xt_current, xt_next):\n",
    "    return tf.log(T[xt_current, xt_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0 = tf.constant([0.1, 0.1, 0.3, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0, 2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (2, 1), (1, 3)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sequence of transitions:\n",
    "list(zip(x[:-1], x[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Log_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.log(pi_0[x[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest version of scan repeatedly applies the callable fn to a sequence of elements from first to last. The elements are made of the tensors unpacked from elems on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn. If initializer is None, elems must contain at least one element, and its first element is used as the initializer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fn: The callable to be performed. It accepts two arguments. The first will have the same structure as initializer if one is provided, otherwise it will have the same structure as elems. The second will have the same (possibly nested) structure as elems. Its output must have the same structure as initializer if one is provided, otherwise it must have the same structure as elems.\n",
    "\n",
    "- elems: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice index 0 of dimension 0 out of bounds. for 'scan/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 0 of dimension 0 out of bounds. for 'scan/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-1f929e265b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransition_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(fn, elems, initializer, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    556\u001b[0m         ops.convert_to_tensor(elem, name=\"elem\") for elem in elems_flat]\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;31m# TensorArrays are always flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    758\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   7812\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7813\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7814\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   7815\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7816\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3290\u001b[0m           op_def=op_def)\n\u001b[1;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[0;32m-> 3292\u001b[0;31m                              compute_device=compute_device)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;31m# compute_shapes argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m     \u001b[0;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2467\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/prob-prog/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: slice index 0 of dimension 0 out of bounds. for 'scan/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>."
     ]
    }
   ],
   "source": [
    "log_prob = tf.scan(\n",
    "    fn=transition_function,\n",
    "    elems=list(zip(x[:-1], x[1:])),\n",
    "    initializer=tf.log(pi_0[x[0]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = log(T())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "sum = tf.foldl(lambda a, x: a + x, [elems, elems])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_log_probs = self._log_trans\n",
    "\n",
    "def forward_step(log_probs, _):\n",
    "    return _log_vector_matrix(log_probs, transition_log_probs)\n",
    "\n",
    "dummy_index = tf.zeros(_num_steps - 1, dtype=tf.float32)\n",
    "\n",
    "forward_log_probs = tf.scan(forward_step, dummy_index,\n",
    "                                  initializer=initial_log_probs,\n",
    "                                  name=\"forward_log_probs\")\n",
    "\n",
    "forward_log_probs = tf.concat([[initial_log_probs], forward_log_probs],\n",
    "                                    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_vector_matrix(vs, ms):\n",
    "    \"\"\"Multiply tensor of vectors by matrices assuming values stored are logs.\"\"\"\n",
    "\n",
    "    return tf.reduce_logsumexp(vs[..., tf.newaxis] + ms, axis=-2)\n",
    "    # vs[..., tf.newaxis] is equivalent to vs[:,:,:,tf.newaxis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
